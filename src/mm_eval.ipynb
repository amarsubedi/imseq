{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Evaluation  for MovingMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.expanduser(\"~/libs\"))\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensortools as tt\n",
    "\n",
    "from model.frame_prediction import LSTMConv2DPredictionModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data\n",
    "INPUT_SEQ_LENGTH = 10\n",
    "OUTPUT_SEQ_LENGTH = 10\n",
    "\n",
    "# Evaluation\n",
    "EVAL_BATCH_SIZE = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# validation while training\n",
    "OUT_DIR_NAME = \"out-eval\"\n",
    "NUM_SAMPLES = 4\n",
    "GIF_FPS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Directory Paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ROOT_DIR = \"/work/sauterme/\"\n",
    "DATA_DIR = ROOT_DIR + \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR = ROOT_DIR + \"train/mm/ss/3l3i5hp/c326464k533s212bn/wd1e-05/LV\"\n",
    "\n",
    "assert os.path.exists(TRAIN_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "AS_BINARY = True\n",
    "dataset_valid = tt.datasets.moving_mnist.MovingMNISTValidDataset(DATA_DIR,\n",
    "                                                                 input_shape=[INPUT_SEQ_LENGTH, 64, 64, 1],\n",
    "                                                                 target_shape=[OUTPUT_SEQ_LENGTH, 64, 64, 1],\n",
    "                                                                 as_binary=AS_BINARY)\n",
    "dataset_test = tt.datasets.moving_mnist.MovingMNISTTestDataset(DATA_DIR,\n",
    "                                                               input_seq_length=INPUT_SEQ_LENGTH,\n",
    "                                                               target_seq_length=OUTPUT_SEQ_LENGTH,\n",
    "                                                               as_binary=AS_BINARY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GPU_ID = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "runtime = tt.core.DefaultRuntime(train_dir=TRAIN_DIR, gpu_devices=[GPU_ID])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "runtime.list_checkpoints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CHECKPOINT = tt.core.LATEST_CHECKPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "runtime.register_datasets(None, dataset_valid, dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "runtime.register_model(LSTMConv2DPredictionModel(main_loss=tt.loss.bce))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider to restore the **EMA variables** as well when building the model. These might generate worse results in models using batch-normalization, since the shaddow variables might get restored properly..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "runtime.build(restore_checkpoint=CHECKPOINT, restore_model_params=True,\n",
    "              restore_ema_variables=False, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "runtime.validate(EVAL_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "runtime.test(EVAL_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations\n",
    "On which dataset we want to test on on the next section. For sequences > 10, we have to use the validation set..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_eval = dataset_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random prediction\n",
    "Either as **binary** (like in training) or **float** (as in raw dataset)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_animation(dir_path, inputs, targets, predictions, fps):\n",
    "    concat_tgt = np.concatenate((inputs, targets))\n",
    "    concat_pred = np.concatenate((inputs, predictions))\n",
    "\n",
    "    tt.utils.video.write_multi_gif(os.path.join(dir_path, \"anim-{:02d}.gif\".format(i)),\n",
    "                                   [concat_tgt, concat_pred],\n",
    "                                   fps=fps, pad_value=1.0)\n",
    "\n",
    "    tt.utils.video.write_multi_image_sequence(os.path.join(dir_path, \"timeline-{:02d}.png\".format(i)),\n",
    "                                              [concat_tgt, concat_pred],\n",
    "                                              pad_value=1.0)\n",
    "\n",
    "def show(inputs, targets, predictions, rows=2):\n",
    "    tt.visualization.display_batch(inputs, ncols=5, nrows=rows, title=\"Inputs\")\n",
    "    tt.visualization.display_batch(targets, ncols=5, nrows=rows, title=\"Targets\")\n",
    "    tt.visualization.display_batch(predictions, ncols=5, nrows=rows, title=\"Predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dir_path = os.path.join(runtime.train_dir, OUT_DIR_NAME, \"random\")\n",
    "\n",
    "inputs, targets = dataset_eval.get_batch(NUM_SAMPLES)\n",
    "\n",
    "predictions = runtime.predict(inputs)\n",
    "\n",
    "show(inputs[0], targets[0], predictions[0])\n",
    "for i in range(inputs.shape[0]):\n",
    "    write_animation(dir_path, inputs[i], targets[i], predictions[i], GIF_FPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specific Predictions\n",
    "We are using the inputs used in _Unsupervised Learning with LSTMs_ cropped out of the paper. These consist of two normal sequences, one sequence with only one character and one sequence with three characters..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SOURCE_PATH = \"assets/other/moving_mnist/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_sequence(dir_path, seq_id):\n",
    "    image_list = []\n",
    "    for i in range(INPUT_SEQ_LENGTH+OUTPUT_SEQ_LENGTH):\n",
    "        image_path = os.path.join(dir_path, str(seq_id), \"{:02d}.png\".format(i))\n",
    "        image = tt.utils.image.read(image_path, color_flags = cv2.IMREAD_GRAYSCALE)\n",
    "        image_list.append(image)\n",
    "    seq = np.array(image_list)\n",
    "    seq = seq / 255.0\n",
    "    seq = np.expand_dims(seq, 0)\n",
    "    return seq[:,:INPUT_SEQ_LENGTH] , seq[:,INPUT_SEQ_LENGTH:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dir_path = os.path.join(runtime.train_dir, OUT_DIR_NAME, \"spec\")\n",
    "\n",
    "for i in range(6):\n",
    "    inputs, targets = read_sequence(SOURCE_PATH, i)\n",
    "    predictions = runtime.predict(inputs)\n",
    "    \n",
    "    show(inputs[0], targets[0], predictions[0])\n",
    "    write_animation(dir_path, inputs[0], targets[0], predictions[0], GIF_FPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Bigger Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SCALE_FACTOR = 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "runtime.unregister_datasets()\n",
    "runtime.build(restore_checkpoint=CHECKPOINT, restore_model_params=True,\n",
    "              restore_ema_variables=False,\n",
    "              input_shape=[INPUT_SEQ_LENGTH, int(64 * SCALE_FACTOR), int(64 * SCALE_FACTOR), 1],\n",
    "              target_shape=[OUTPUT_SEQ_LENGTH, int(64 * SCALE_FACTOR), int(64 * SCALE_FACTOR), 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dir_path = os.path.join(runtime.train_dir, OUT_DIR_NAME, \"scaled\")\n",
    "\n",
    "inputs, targets = dataset_eval.get_batch(NUM_SAMPLES)\n",
    "\n",
    "inputs = np.reshape(inputs, [-1, 64, 64, 1])\n",
    "targets = np.reshape(targets, [-1, 64, 64, 1])\n",
    "\n",
    "inputs = np.split(inputs, inputs.shape[0])\n",
    "targets = np.split(targets, targets.shape[0])\n",
    "\n",
    "for i in range(len(inputs)):\n",
    "    current = np.squeeze(inputs[i], 0)\n",
    "    inputs[i] = tt.utils.image.resize(current, SCALE_FACTOR)\n",
    "inputs = np.stack(inputs)\n",
    "\n",
    "for i in range(len(targets)):\n",
    "    current = np.squeeze(targets[i], 0)\n",
    "    targets[i] = tt.utils.image.resize(current, SCALE_FACTOR)\n",
    "targets = np.stack(targets)\n",
    "\n",
    "inputs = np.reshape(inputs, [-1, INPUT_SEQ_LENGTH, int(64 * SCALE_FACTOR), int(64 * SCALE_FACTOR), 1])\n",
    "targets = np.reshape(targets, [-1, OUTPUT_SEQ_LENGTH, int(64 * SCALE_FACTOR), int(64 * SCALE_FACTOR), 1])\n",
    "\n",
    "predictions = runtime.predict(inputs)\n",
    "\n",
    "show(inputs[0], targets[0], predictions[0])\n",
    "for i in range(inputs.shape[0]):\n",
    "    write_animation(dir_path, inputs[i], targets[i], predictions[i], GIF_FPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Zero-Padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SIZE_FACTOR = 2.0\n",
    "AS_BINARY = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this, we have to use the **validation set**, because it allows variable size of the image..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_eval = tt.datasets.moving_mnist.MovingMNISTValidDataset(\n",
    "    DATA_DIR, input_shape=[INPUT_SEQ_LENGTH, int(64 * SIZE_FACTOR), int(64 * SIZE_FACTOR), 1],\n",
    "    target_shape=[OUTPUT_SEQ_LENGTH, int(64 * SIZE_FACTOR), int(64 * SIZE_FACTOR), 1],\n",
    "    as_binary=AS_BINARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "runtime.register_datasets(valid_ds=dataset_eval)\n",
    "runtime.build(restore_checkpoint=CHECKPOINT, restore_model_params=True,\n",
    "              restore_ema_variables=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dir_path = os.path.join(runtime.train_dir, OUT_DIR_NAME, \"padded\")\n",
    "\n",
    "inputs, targets = dataset_eval.get_batch(NUM_SAMPLES)\n",
    "\n",
    "predictions = runtime.predict(inputs)\n",
    "\n",
    "show(inputs[0], targets[0], predictions[0])\n",
    "for i in range(inputs.shape[0]):\n",
    "    write_animation(dir_path, inputs[i], targets[i], predictions[i], GIF_FPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Longer Time Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data\n",
    "INPUT_SEQ_LENGTH = 10\n",
    "OUTPUT_SEQ_LENGTH = 50\n",
    "\n",
    "AS_BINARY = True\n",
    "dataset_eval = tt.datasets.moving_mnist.MovingMNISTValidDataset(DATA_DIR,\n",
    "                                                                input_shape=[INPUT_SEQ_LENGTH, 64, 64, 1],\n",
    "                                                                target_shape=[OUTPUT_SEQ_LENGTH, 64, 64, 1],\n",
    "                                                                as_binary=AS_BINARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "runtime.register_datasets(None, dataset_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "runtime.build(restore_checkpoint=CHECKPOINT, restore_model_params=True,\n",
    "              restore_ema_variables=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dir_path = os.path.join(runtime.train_dir, OUT_DIR_NAME, \"long\")\n",
    "\n",
    "inputs, targets = dataset_eval.get_batch(NUM_SAMPLES)\n",
    "\n",
    "predictions = runtime.predict(inputs)\n",
    "\n",
    "show(inputs[0], targets[0], predictions[0], rows=10)\n",
    "for i in range(inputs.shape[0]):\n",
    "    write_animation(dir_path, inputs[i], targets[i], predictions[i], GIF_FPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
