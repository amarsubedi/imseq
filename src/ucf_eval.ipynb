{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Evaluation  for UCF-101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.expanduser(\"~/libs\"))\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensortools as tt\n",
    "\n",
    "from model.frame_prediction2 import LSTMConv2DPredictionModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data\n",
    "INPUT_SEQ_LENGTH = 10\n",
    "OUTPUT_SEQ_LENGTH = 10\n",
    "\n",
    "# Evaluation\n",
    "EVAL_BATCH_SIZE = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# validation while training\n",
    "OUT_DIR_NAME = \"out-eval\"\n",
    "NUM_SAMPLES = 10\n",
    "GIF_FPS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Directory Paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ROOT_DIR = \"/work/sauterme/\"\n",
    "DATA_DIR = ROOT_DIR + \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR = ROOT_DIR + \"train/ucf/ss/2l3i5hp/c326464k533s121bn/wd1e-05/mae/triplet/YN\"\n",
    "\n",
    "assert os.path.exists(TRAIN_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_valid = tt.datasets.ucf101.UCF101ValidDataset(DATA_DIR,\n",
    "                                                      input_seq_length=INPUT_SEQ_LENGTH,\n",
    "                                                      target_seq_length=OUTPUT_SEQ_LENGTH,\n",
    "                                                      image_scale_factor=0.5, double_with_flipped=True,\n",
    "                                                      crop_size=[32, 32], repetitions_per_epoche=8,\n",
    "                                                      skip_less_movement=True)\n",
    "dataset_test = tt.datasets.ucf101.UCF101TestDataset(DATA_DIR,\n",
    "                                                    input_seq_length=INPUT_SEQ_LENGTH,\n",
    "                                                    target_seq_length=OUTPUT_SEQ_LENGTH,\n",
    "                                                    image_scale_factor=0.5, double_with_flipped=True,\n",
    "                                                    crop_size=[32, 32], repetitions_per_epoche=8,\n",
    "                                                    skip_less_movement=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GPU_ID = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "runtime = tt.core.DefaultRuntime(train_dir=TRAIN_DIR, gpu_devices=[GPU_ID])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "runtime.list_checkpoints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CHECKPOINT = tt.core.LATEST_CHECKPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "runtime.register_datasets(None, dataset_valid, dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "runtime.register_model(LSTMConv2DPredictionModel(main_loss=tt.loss.bce))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider to restore the **EMA variables** as well when building the model. These might generate worse results in models using batch-normalization, since the shaddow variables might get restored properly..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "runtime.build(restore_checkpoint=CHECKPOINT, restore_model_params=True,\n",
    "              restore_ema_variables=False, eval_mode=True, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "runtime.validate(EVAL_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "runtime.test(EVAL_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations\n",
    "On which dataset we want to test on on the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_eval = dataset_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random prediction\n",
    "Either as **binary** (like in training) or **float** (as in raw dataset)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_animation(dir_path, inputs, targets, predictions, fps):\n",
    "    concat_tgt = np.concatenate((inputs, targets))\n",
    "    concat_pred = np.concatenate((inputs, predictions))\n",
    "\n",
    "    tt.utils.video.write_multi_gif(os.path.join(dir_path, \"anim-{:02d}.gif\".format(i)),\n",
    "                                   [concat_tgt, concat_pred],\n",
    "                                   fps=fps, pad_value=1.0)\n",
    "\n",
    "    tt.utils.video.write_multi_image_sequence(os.path.join(dir_path, \"timeline-{:02d}.png\".format(i)),\n",
    "                                              [concat_tgt, concat_pred],\n",
    "                                              pad_value=1.0)\n",
    "\n",
    "def show(inputs, targets, predictions, rows=2):\n",
    "    tt.visualization.display_batch(inputs, ncols=5, nrows=rows, title=\"Inputs\")\n",
    "    tt.visualization.display_batch(targets, ncols=5, nrows=rows, title=\"Targets\")\n",
    "    tt.visualization.display_batch(predictions, ncols=5, nrows=rows, title=\"Predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dir_path = os.path.join(runtime.train_dir, OUT_DIR_NAME, \"random\")\n",
    "\n",
    "inputs, targets = dataset_eval.get_batch(NUM_SAMPLES)\n",
    "\n",
    "predictions = runtime.predict(inputs)\n",
    "\n",
    "show(inputs[0], targets[0], predictions[0])\n",
    "for i in range(inputs.shape[0]):\n",
    "    write_animation(dir_path, inputs[i], targets[i], predictions[i], GIF_FPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specific Predictions TBD !!!\n",
    "We are using the inputs used in _Gutgub: Adversarial Video Generation_ cropped out of the website. These consist of two sequences..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SOURCE_PATH_FORMAT = \"assets/other/ucf101/{}/32\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_sequence(dir_path, seq_id):\n",
    "    image_list = []\n",
    "    for i in range(INPUT_SEQ_LENGTH+OUTPUT_SEQ_LENGTH):\n",
    "        image_path = os.path.join(dir_path.format(str(seq_id)), \"{:02d}.png\".format(i))\n",
    "        image = tt.utils.image.read(image_path)\n",
    "        image_list.append(image)\n",
    "    seq = np.array(image_list)\n",
    "    seq = seq / 255.0\n",
    "    seq = np.expand_dims(seq, 0)\n",
    "    return seq[:,:INPUT_SEQ_LENGTH] , seq[:,INPUT_SEQ_LENGTH:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dir_path = os.path.join(runtime.train_dir, OUT_DIR_NAME, \"spec\")\n",
    "\n",
    "for i in range(2):\n",
    "    inputs, targets = read_sequence(SOURCE_PATH_FORMAT, i)\n",
    "    predictions = runtime.predict(inputs)\n",
    "    \n",
    "    show(inputs[0], targets[0], predictions[0])\n",
    "    write_animation(dir_path, inputs[0], targets[0], predictions[0], GIF_FPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Fulll Image\n",
    "Is the FCN model worth it? :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_valid = tt.datasets.ucf101.UCF101ValidDataset(DATA_DIR,\n",
    "                                                      input_seq_length=INPUT_SEQ_LENGTH,\n",
    "                                                      target_seq_length=OUTPUT_SEQ_LENGTH,\n",
    "                                                      image_scale_factor=0.5, double_with_flipped=False,\n",
    "                                                      crop_size=[32, 32], repetitions_per_epoche=8,\n",
    "                                                      skip_less_movement=False)\n",
    "dataset_test = tt.datasets.ucf101.UCF101TestDataset(DATA_DIR,\n",
    "                                                    input_seq_length=INPUT_SEQ_LENGTH,\n",
    "                                                    target_seq_length=OUTPUT_SEQ_LENGTH,\n",
    "                                                    image_scale_factor=0.5, double_with_flipped=False,\n",
    "                                                    crop_size=[32, 32], repetitions_per_epoche=8,\n",
    "                                                    skip_less_movement=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_eval = dataset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "runtime.register_datasets(None, dataset_valid, dataset_test)\n",
    "runtime.build(restore_checkpoint=CHECKPOINT, restore_model_params=True,\n",
    "              restore_ema_variables=False, eval_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dir_path = os.path.join(runtime.train_dir, OUT_DIR_NAME, \"full\")\n",
    "\n",
    "inputs, targets = dataset_eval.get_batch(NUM_SAMPLES)\n",
    "\n",
    "predictions = runtime.predict(inputs)\n",
    "\n",
    "show(inputs[0], targets[0], predictions[0])\n",
    "for i in range(inputs.shape[0]):\n",
    "    write_animation(dir_path, inputs[i], targets[i], predictions[i], GIF_FPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Full Image - Longer Time Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data\n",
    "INPUT_SEQ_LENGTH = 10\n",
    "OUTPUT_SEQ_LENGTH = 20\n",
    "\n",
    "dataset_valid = tt.datasets.ucf101.UCF101ValidDataset(DATA_DIR,\n",
    "                                                      input_seq_length=INPUT_SEQ_LENGTH,\n",
    "                                                      target_seq_length=OUTPUT_SEQ_LENGTH,\n",
    "                                                      image_scale_factor=0.5, double_with_flipped=False,\n",
    "                                                      crop_size=[32, 32], repetitions_per_epoche=8,\n",
    "                                                      skip_less_movement=False)\n",
    "dataset_test = tt.datasets.ucf101.UCF101TestDataset(DATA_DIR,\n",
    "                                                    input_seq_length=INPUT_SEQ_LENGTH,\n",
    "                                                    target_seq_length=OUTPUT_SEQ_LENGTH,\n",
    "                                                    image_scale_factor=0.5, double_with_flipped=False,\n",
    "                                                    crop_size=[32, 32], repetitions_per_epoche=8,\n",
    "                                                    skip_less_movement=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_eval = dataset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "runtime.register_datasets(None, dataset_valid, dataset_test)\n",
    "runtime.build(restore_checkpoint=CHECKPOINT, restore_model_params=True,\n",
    "              restore_ema_variables=False, eval_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dir_path = os.path.join(runtime.train_dir, OUT_DIR_NAME, \"full-long\")\n",
    "\n",
    "inputs, targets = dataset_eval.get_batch(NUM_SAMPLES)\n",
    "\n",
    "predictions = runtime.predict(inputs)\n",
    "\n",
    "show(inputs[0], targets[0], predictions[0])\n",
    "for i in range(inputs.shape[0]):\n",
    "    write_animation(dir_path, inputs[i], targets[i], predictions[i], GIF_FPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
