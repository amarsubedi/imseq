{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training  for MovingMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.expanduser(\"~/libs\"))\n",
    "\n",
    "import random\n",
    "import string\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensortools as tt\n",
    "\n",
    "from model.frame_prediction import LSTMConv2DPredictionModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data\n",
    "INPUT_SEQ_LENGTH = 10\n",
    "OUTPUT_SEQ_LENGTH = 10\n",
    "\n",
    "# model\n",
    "WEIGHT_DECAY = 1e-5\n",
    "CONV_FILTERS = [32, 64, 64]\n",
    "CONV_KSIZES  = [(5,5),(3,3),(3,3)]\n",
    "CONV_STRIDES = [(2,2),(1,1),(2,2)]\n",
    "CONV_BN      = True\n",
    "CONV_BIAS    = 0.1\n",
    "OUTPUT_ACTIV = tf.nn.sigmoid\n",
    "LSTM_LAYERS       = 2\n",
    "LSTM_KSIZE_INPUT  = (3, 3)\n",
    "LSTM_KSIZE_HIDDEN = (5, 5)\n",
    "LSTM_PEEPHOLES    = True\n",
    "MAIN_LOSS       = tt.loss.bce\n",
    "MAIN_LOSS_ALPHA = 1.0\n",
    "GDL_LOSS_ALPHA  = 1.0\n",
    "SCHED_SAMPLING_DECAY = 1000.0\n",
    "\n",
    "# optimizer\n",
    "LR_INIT = 0.001\n",
    "LR_DECAY_INTERVAL = 1000\n",
    "LR_DECAY_FACTOR = 0.90\n",
    "\n",
    "# training\n",
    "BATCH_SIZE = 32\n",
    "EVAL_BATCH_SIZE = 50\n",
    "MAX_STEPS = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# validation while training\n",
    "KEEP_CHECKPOINTS = 20\n",
    "OUT_DIR_NAME = \"out-train\"\n",
    "NUM_SAMPLES = 4\n",
    "GIF_FPS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Directory Paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ROOT_DIR = \"/work/sauterme/\"\n",
    "DATA_DIR = ROOT_DIR + \"data\"\n",
    "TRAIN_DIR_BASE = os.path.join(ROOT_DIR, \"train\", \"mm\",\n",
    "                              \"{}\".format(\"ss\" if SCHED_SAMPLING_DECAY is not None else \"as\"),\n",
    "                              \"{}l{}i{}h{}\".format(LSTM_LAYERS, LSTM_KSIZE_INPUT[0], LSTM_KSIZE_HIDDEN[0],\n",
    "                                                   \"p\" if LSTM_PEEPHOLES else \"\"),\n",
    "                              \"c{}k{}s{}{}\".format(\"\".join([str(f) for f in CONV_FILTERS]),\n",
    "                                                   \"\".join([str(k[0]) for k in CONV_KSIZES]),\n",
    "                                                   \"\".join([str(s[0]) for s in CONV_STRIDES]),\n",
    "                                                   \"bn\" if CONV_BN else \"\"),\n",
    "                              \"wd{:.0e}\".format(WEIGHT_DECAY))\n",
    "\n",
    "TRAIN_DIR = os.path.join(TRAIN_DIR_BASE,\n",
    "                         \"\".join(random.choice(string.ascii_uppercase) for _ in range(2)))\n",
    "\n",
    "# check for conflict\n",
    "print(\"Training directory  : {}\".format(TRAIN_DIR))\n",
    "print(\"Is new training     : {}\".format(not os.path.exists(TRAIN_DIR_BASE)))\n",
    "\n",
    "assert not os.path.exists(TRAIN_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "AS_BINARY = True if MAIN_LOSS.__name__ == 'bce' else False\n",
    "print(\"MovingMNIST as binary data: {}\".format(AS_BINARY))\n",
    "\n",
    "dataset_train = tt.datasets.moving_mnist.MovingMNISTTrainDataset(DATA_DIR,\n",
    "                                                                 input_shape=[INPUT_SEQ_LENGTH, 64, 64, 1],\n",
    "                                                                 target_shape=[OUTPUT_SEQ_LENGTH, 64, 64, 1],\n",
    "                                                                 as_binary=AS_BINARY)\n",
    "dataset_valid = tt.datasets.moving_mnist.MovingMNISTValidDataset(DATA_DIR,\n",
    "                                                                 input_shape=[INPUT_SEQ_LENGTH, 64, 64, 1],\n",
    "                                                                 target_shape=[OUTPUT_SEQ_LENGTH, 64, 64, 1],\n",
    "                                                                 as_binary=AS_BINARY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GPU_ID = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "runtime = tt.core.DefaultRuntime(train_dir=TRAIN_DIR, gpu_devices=[GPU_ID])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "runtime.register_datasets(dataset_train, dataset_valid)\n",
    "runtime.register_model(LSTMConv2DPredictionModel(weight_decay=WEIGHT_DECAY,\n",
    "                                                 filters=CONV_FILTERS, ksizes=CONV_KSIZES,\n",
    "                                                 strides=CONV_STRIDES, bias_init=CONV_BIAS,\n",
    "                                                 output_activation=OUTPUT_ACTIV,\n",
    "                                                 bn_feature_enc=CONV_BN, bn_feature_dec=CONV_BN, \n",
    "                                                 lstm_layers=LSTM_LAYERS, \n",
    "                                                 lstm_ksize_input=LSTM_KSIZE_INPUT,\n",
    "                                                 lstm_ksize_hidden=LSTM_KSIZE_HIDDEN,\n",
    "                                                 lstm_use_peepholes=LSTM_PEEPHOLES,\n",
    "                                                 scheduled_sampling_decay_rate=SCHED_SAMPLING_DECAY,\n",
    "                                                 main_loss=MAIN_LOSS,alpha_main_loss=MAIN_LOSS_ALPHA,\n",
    "                                                 alpha_gdl_loss=GDL_LOSS_ALPHA))\n",
    "runtime.register_optimizer(tt.training.Optimizer(tt.training.ADAM,\n",
    "                                                 LR_INIT,\n",
    "                                                 LR_DECAY_INTERVAL,\n",
    "                                                 LR_DECAY_FACTOR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "runtime.build(max_checkpoints_to_keep=KEEP_CHECKPOINTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_animations(rt, dataset, gstep):\n",
    "    root = os.path.join(rt.train_dir, OUT_DIR_NAME, \"{:06d}\".format(gstep))\n",
    "    x, y = dataset.get_batch(NUM_SAMPLES)\n",
    "    pred = rt.predict(x)\n",
    "\n",
    "    for i in range(NUM_SAMPLES):\n",
    "        concat_y = np.concatenate((x[i], y[i]))\n",
    "        concat_pred = np.concatenate((x[i], pred[i]))\n",
    "\n",
    "        tt.utils.video.write_multi_gif(os.path.join(root, \"anim-{:02d}.gif\".format(i)),\n",
    "                                       [concat_y, concat_pred],\n",
    "                                       fps=GIF_FPS, pad_value=1.0)\n",
    "\n",
    "        tt.utils.video.write_multi_image_sequence(os.path.join(root, \"timeline-{:02d}.png\".format(i)),\n",
    "                                                  [concat_y, concat_pred],\n",
    "                                                  pad_value=1.0)\n",
    "\n",
    "def on_valid(rt, gstep):\n",
    "    write_animations(rt, rt.datasets.valid, gstep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "runtime.train(BATCH_SIZE, EVAL_BATCH_SIZE, steps=MAX_STEPS, on_validate=on_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "runtime.validate(EVAL_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Terminate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "runtime.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
