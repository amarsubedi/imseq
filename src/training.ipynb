{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMSEQ TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Force matplotlib to use inline rendering\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# add path to libraries for ipython\n",
    "sys.path.append(os.path.expanduser(\"~/libs\"))\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensortools as tt\n",
    "\n",
    "from model.frame_prediction import LSTMConv2DPredictionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ROOT_DIR = \"/work/sauterme/\"\n",
    "DATA_DIR = ROOT_DIR + \"data\"\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EVAL_BATCH_SIZE = 50\n",
    "\n",
    "WEIGHT_DECAY = 1e-5\n",
    "\n",
    "INPUT_SEQ_LENGTH = 10\n",
    "OUTPUT_SEQ_LENGTH = 10\n",
    "\n",
    "INITIAL_LR = 0.001\n",
    "LR_DECAY_STEP_INTERVAL = 1000\n",
    "LR_DECAY_FACTOR = 0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_train = tt.datasets.moving_mnist.MovingMNISTTrainDataset(DATA_DIR,\n",
    "                                                                 input_shape=[INPUT_SEQ_LENGTH, 64, 64, 1],\n",
    "                                                                 target_shape=[OUTPUT_SEQ_LENGTH, 64, 64, 1],\n",
    "                                                                 as_binary=True)\n",
    "dataset_valid = tt.datasets.moving_mnist.MovingMNISTValidDataset(DATA_DIR,\n",
    "                                                                 input_shape=[INPUT_SEQ_LENGTH, 64, 64, 1],\n",
    "                                                                 target_shape=[OUTPUT_SEQ_LENGTH, 64, 64, 1],\n",
    "                                                                 as_binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TRAIN_DIR = ROOT_DIR + \"train/wd1e5_64filters_peep_no-input-bn\"\n",
    "TRAIN_DIR = ROOT_DIR + \"train/refac_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "runtime = tt.core.DefaultRuntime(train_dir=TRAIN_DIR, gpu_devices=[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "runtime.register_datasets(dataset_train, dataset_valid, dataset_valid)\n",
    "runtime.register_model(LSTMConv2DPredictionModel(weight_decay=WEIGHT_DECAY,\n",
    "                                                 filters=[32, 64, 64], ksizes=[(5,5),(3,3),(3,3)],\n",
    "                                                 strides=[(2,2),(1,1),(2,2)], bias_init=0.1,\n",
    "                                                 output_activation=tf.nn.sigmoid,\n",
    "                                                 bn_feature_enc=True, bn_feature_dec=True, \n",
    "                                                 lstm_layers=2, \n",
    "                                                 lstm_ksize_input=(3, 3), lstm_ksize_hidden=(3,3),\n",
    "                                                 lstm_use_peepholes=True, lstm_cell_clip=None,\n",
    "                                                 lstm_bn_input_hidden=False, lstm_bn_hidden_hidden=False,\n",
    "                                                 lstm_bn_peepholes=False))\n",
    "runtime.register_optimizer(tt.training.Optimizer('adam',\n",
    "                                                 INITIAL_LR,\n",
    "                                                 LR_DECAY_STEP_INTERVAL,\n",
    "                                                 LR_DECAY_FACTOR))\n",
    "runtime.build(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_animations(rt, dataset, gstep):\n",
    "    samples = 4\n",
    "    root = os.path.join(rt.train_dir, \"out\", \"{:06d}\".format(gstep))\n",
    "    x, y = dataset.get_batch(samples)\n",
    "    pred = rt.predict(x)\n",
    "\n",
    "    # concat x to y and prediction\n",
    "    for i in range(samples):\n",
    "        concat_y = np.concatenate((x[i], y[i]))\n",
    "        concat_pred = np.concatenate((x[i], pred[i]))\n",
    "\n",
    "        tt.utils.video.write_multi_gif(os.path.join(root, \"anim-{:02d}.gif\".format(i)),\n",
    "                                       [concat_y, concat_pred],\n",
    "                                       fps=5, pad_value=1.0)\n",
    "\n",
    "        tt.utils.video.write_multi_image_sequence(os.path.join(root, \"timeline-{:02d}.png\".format(i)),\n",
    "                                                  [concat_y, concat_pred],\n",
    "                                                  pad_value=1.0)\n",
    "    \n",
    "def on_valid(rt, gstep):\n",
    "    write_animations(rt, rt.datasets.valid, gstep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "runtime.train(BATCH_SIZE, EVAL_BATCH_SIZE,\n",
    "              steps=50000, on_validate=on_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "runtime.validate(EVAL_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "runtime.test(EVAL_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x, y = dataset_valid.get_batch(1)\n",
    "pred = runtime.predict(x)\n",
    "print(x.dtype, y.dtype, pred.dtype)\n",
    "print(x.min(), x.max())\n",
    "print(y.min(), y.max())\n",
    "print(pred.min(), pred.max())\n",
    "tt.visualization.display_batch(x[0], nrows=2, ncols=5, title=\"Input\")\n",
    "tt.visualization.display_batch(y[0], nrows=2, ncols=5, title=\"GT-Future\")\n",
    "tt.visualization.display_batch(pred[0], nrows=2, ncols=5, title=\"GT-Prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "write_animations(runtime, dataset_valid, 999999999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Terminate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "runtime.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
