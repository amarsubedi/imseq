{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Evaluation  for MsPacman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.expanduser(\"~/libs\"))\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensortools as tt\n",
    "\n",
    "from model.frame_prediction import LSTMConv2DPredictionModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data\n",
    "INPUT_SEQ_LENGTH = 8\n",
    "OUTPUT_SEQ_LENGTH = 8\n",
    "\n",
    "# Evaluation\n",
    "EVAL_BATCH_SIZE = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# validation while training\n",
    "OUT_DIR_NAME = \"out-eval\"\n",
    "NUM_SAMPLES = 10\n",
    "GIF_FPS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Directory Paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ROOT_DIR = \"/work/sauterme/\"\n",
    "DATA_DIR = ROOT_DIR + \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR = ROOT_DIR + \"train/pac/ss/2l3i5hp/c326464k533s121bn/wd1e-05/mse/QQ\"\n",
    "\n",
    "assert os.path.exists(TRAIN_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Ms_Pacman.zip has already been extracted.\n",
      "File Ms_Pacman.zip has already been extracted.\n"
     ]
    }
   ],
   "source": [
    "dataset_valid = tt.datasets.ms_pacman.MsPacmanValidDataset(DATA_DIR,\n",
    "                                                           input_seq_length=INPUT_SEQ_LENGTH,\n",
    "                                                           target_seq_length=OUTPUT_SEQ_LENGTH,\n",
    "                                                           crop_size=[32, 32])\n",
    "dataset_test = tt.datasets.ms_pacman.MsPacmanTestDataset(DATA_DIR,\n",
    "                                                         input_seq_length=INPUT_SEQ_LENGTH,\n",
    "                                                         target_seq_length=OUTPUT_SEQ_LENGTH,\n",
    "                                                         crop_size=[32, 32],\n",
    "                                                         skip_less_movement=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GPU_ID = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "runtime = tt.core.DefaultRuntime(train_dir=TRAIN_DIR, gpu_devices=[GPU_ID])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/work/sauterme/train/pac/ss/2l3i5hp/c326464k533s121bn/wd1e-05/mse/QQ/model.ckpt-100000',\n",
       " '/work/sauterme/train/pac/ss/2l3i5hp/c326464k533s121bn/wd1e-05/mse/QQ/model.ckpt-62000',\n",
       " '/work/sauterme/train/pac/ss/2l3i5hp/c326464k533s121bn/wd1e-05/mse/QQ/model.ckpt-64000',\n",
       " '/work/sauterme/train/pac/ss/2l3i5hp/c326464k533s121bn/wd1e-05/mse/QQ/model.ckpt-66000',\n",
       " '/work/sauterme/train/pac/ss/2l3i5hp/c326464k533s121bn/wd1e-05/mse/QQ/model.ckpt-68000',\n",
       " '/work/sauterme/train/pac/ss/2l3i5hp/c326464k533s121bn/wd1e-05/mse/QQ/model.ckpt-70000',\n",
       " '/work/sauterme/train/pac/ss/2l3i5hp/c326464k533s121bn/wd1e-05/mse/QQ/model.ckpt-72000',\n",
       " '/work/sauterme/train/pac/ss/2l3i5hp/c326464k533s121bn/wd1e-05/mse/QQ/model.ckpt-74000',\n",
       " '/work/sauterme/train/pac/ss/2l3i5hp/c326464k533s121bn/wd1e-05/mse/QQ/model.ckpt-76000',\n",
       " '/work/sauterme/train/pac/ss/2l3i5hp/c326464k533s121bn/wd1e-05/mse/QQ/model.ckpt-78000',\n",
       " '/work/sauterme/train/pac/ss/2l3i5hp/c326464k533s121bn/wd1e-05/mse/QQ/model.ckpt-80000',\n",
       " '/work/sauterme/train/pac/ss/2l3i5hp/c326464k533s121bn/wd1e-05/mse/QQ/model.ckpt-82000',\n",
       " '/work/sauterme/train/pac/ss/2l3i5hp/c326464k533s121bn/wd1e-05/mse/QQ/model.ckpt-84000',\n",
       " '/work/sauterme/train/pac/ss/2l3i5hp/c326464k533s121bn/wd1e-05/mse/QQ/model.ckpt-86000',\n",
       " '/work/sauterme/train/pac/ss/2l3i5hp/c326464k533s121bn/wd1e-05/mse/QQ/model.ckpt-88000',\n",
       " '/work/sauterme/train/pac/ss/2l3i5hp/c326464k533s121bn/wd1e-05/mse/QQ/model.ckpt-90000',\n",
       " '/work/sauterme/train/pac/ss/2l3i5hp/c326464k533s121bn/wd1e-05/mse/QQ/model.ckpt-92000',\n",
       " '/work/sauterme/train/pac/ss/2l3i5hp/c326464k533s121bn/wd1e-05/mse/QQ/model.ckpt-94000',\n",
       " '/work/sauterme/train/pac/ss/2l3i5hp/c326464k533s121bn/wd1e-05/mse/QQ/model.ckpt-96000',\n",
       " '/work/sauterme/train/pac/ss/2l3i5hp/c326464k533s121bn/wd1e-05/mse/QQ/model.ckpt-98000']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runtime.list_checkpoints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CHECKPOINT = tt.core.LATEST_CHECKPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "runtime.register_datasets(None, dataset_valid, dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "runtime.register_model(LSTMConv2DPredictionModel(main_loss=tt.loss.bce))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider to restore the **EMA variables** as well when building the model. These might generate worse results in models using batch-normalization, since the shaddow variables might get restored properly..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model parameters...\n",
      "\n",
      ">>> Model:\n",
      "alpha_ssim_loss   ->  0.0\n",
      "output_activation  ->  TANH\n",
      "lstm_cell_clip    ->  None\n",
      "bias_init         ->  0.0\n",
      "alpha_main_loss   ->  1.0\n",
      "alpha_gdl_loss    ->  1.0\n",
      "lstm_ksize_hidden  ->  (5, 5)\n",
      "lstm_bn_hidden_hidden  ->  False\n",
      "lstm_ksize_input  ->  (3, 3)\n",
      "ksizes            ->  [(5, 5), (3, 3), (3, 3)]\n",
      "lstm_use_peepholes  ->  True\n",
      "lstm_bn_input_hidden  ->  False\n",
      "strides           ->  [(1, 1), (2, 2), (1, 1)]\n",
      "filters           ->  [32, 64, 64]\n",
      "lstm_bn_peepholes  ->  False\n",
      "bn_feature_enc    ->  True\n",
      "main_loss         ->  MSE\n",
      "scheduled_sampling_decay_rate  ->  1000.0\n",
      "bn_feature_dec    ->  True\n",
      "weight_decay      ->  1e-05\n",
      "lstm_layers       ->  2\n",
      "\n",
      "Found 144 update ops.\n",
      "Selected checkpoint file: /work/sauterme/train/pac/ss/2l3i5hp/c326464k533s121bn/wd1e-05/mse/QQ/model.ckpt-100000\n",
      "Restoring variables...\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "conv-encoder/conv1/W:0                                                |     2400\n",
      "conv-encoder/conv1/b:0                                                |       32\n",
      "conv-encoder/conv1_bn/beta:0                                          |       32\n",
      "conv-encoder/conv2/W:0                                                |    18432\n",
      "conv-encoder/conv2/b:0                                                |       64\n",
      "conv-encoder/conv2_bn/beta:0                                          |       64\n",
      "conv-encoder/conv3/W:0                                                |    36864\n",
      "conv-encoder/conv3/b:0                                                |       64\n",
      "conv-encoder/conv3_bn/beta:0                                          |       64\n",
      "lstm-encoder/RNN/MultiRNNC2DCell/Cell0/LSTMC2DCell/Conv_x/i/W:0       |    36864\n",
      "lstm-encoder/RNN/MultiRNNC2DCell/Cell0/LSTMC2DCell/Conv_x/i/b:0       |       64\n",
      "lstm-encoder/RNN/MultiRNNC2DCell/Cell0/LSTMC2DCell/Conv_x/j/W:0       |    36864\n",
      "lstm-encoder/RNN/MultiRNNC2DCell/Cell0/LSTMC2DCell/Conv_x/j/b:0       |       64\n",
      "lstm-encoder/RNN/MultiRNNC2DCell/Cell0/LSTMC2DCell/Conv_x/f/W:0       |    36864\n",
      "lstm-encoder/RNN/MultiRNNC2DCell/Cell0/LSTMC2DCell/Conv_x/f/b:0       |       64\n",
      "lstm-encoder/RNN/MultiRNNC2DCell/Cell0/LSTMC2DCell/Conv_x/o/W:0       |    36864\n",
      "lstm-encoder/RNN/MultiRNNC2DCell/Cell0/LSTMC2DCell/Conv_x/o/b:0       |       64\n",
      "lstm-encoder/RNN/MultiRNNC2DCell/Cell0/LSTMC2DCell/Conv_h/i/W:0       |   102400\n",
      "lstm-encoder/RNN/MultiRNNC2DCell/Cell0/LSTMC2DCell/Conv_h/j/W:0       |   102400\n",
      "lstm-encoder/RNN/MultiRNNC2DCell/Cell0/LSTMC2DCell/Conv_h/f/W:0       |   102400\n",
      "lstm-encoder/RNN/MultiRNNC2DCell/Cell0/LSTMC2DCell/Conv_h/o/W:0       |   102400\n",
      "lstm-encoder/RNN/MultiRNNC2DCell/Cell0/LSTMC2DCell/Conv_peep/i/W:0    |   102400\n",
      "lstm-encoder/RNN/MultiRNNC2DCell/Cell0/LSTMC2DCell/Conv_peep/f/W:0    |   102400\n",
      "lstm-encoder/RNN/MultiRNNC2DCell/Cell0/LSTMC2DCell/Conv_peep/o/W:0    |   102400\n",
      "lstm-encoder/RNN/MultiRNNC2DCell/Cell1/LSTMC2DCell/Conv_x/i/W:0       |    36864\n",
      "lstm-encoder/RNN/MultiRNNC2DCell/Cell1/LSTMC2DCell/Conv_x/i/b:0       |       64\n",
      "lstm-encoder/RNN/MultiRNNC2DCell/Cell1/LSTMC2DCell/Conv_x/j/W:0       |    36864\n",
      "lstm-encoder/RNN/MultiRNNC2DCell/Cell1/LSTMC2DCell/Conv_x/j/b:0       |       64\n",
      "lstm-encoder/RNN/MultiRNNC2DCell/Cell1/LSTMC2DCell/Conv_x/f/W:0       |    36864\n",
      "lstm-encoder/RNN/MultiRNNC2DCell/Cell1/LSTMC2DCell/Conv_x/f/b:0       |       64\n",
      "lstm-encoder/RNN/MultiRNNC2DCell/Cell1/LSTMC2DCell/Conv_x/o/W:0       |    36864\n",
      "lstm-encoder/RNN/MultiRNNC2DCell/Cell1/LSTMC2DCell/Conv_x/o/b:0       |       64\n",
      "lstm-encoder/RNN/MultiRNNC2DCell/Cell1/LSTMC2DCell/Conv_h/i/W:0       |   102400\n",
      "lstm-encoder/RNN/MultiRNNC2DCell/Cell1/LSTMC2DCell/Conv_h/j/W:0       |   102400\n",
      "lstm-encoder/RNN/MultiRNNC2DCell/Cell1/LSTMC2DCell/Conv_h/f/W:0       |   102400\n",
      "lstm-encoder/RNN/MultiRNNC2DCell/Cell1/LSTMC2DCell/Conv_h/o/W:0       |   102400\n",
      "lstm-encoder/RNN/MultiRNNC2DCell/Cell1/LSTMC2DCell/Conv_peep/i/W:0    |   102400\n",
      "lstm-encoder/RNN/MultiRNNC2DCell/Cell1/LSTMC2DCell/Conv_peep/f/W:0    |   102400\n",
      "lstm-encoder/RNN/MultiRNNC2DCell/Cell1/LSTMC2DCell/Conv_peep/o/W:0    |   102400\n",
      "lstm-decoder/RNN/MultiRNNC2DCell/Cell0/LSTMC2DCell/Conv_x/i/W:0       |    36864\n",
      "lstm-decoder/RNN/MultiRNNC2DCell/Cell0/LSTMC2DCell/Conv_x/i/b:0       |       64\n",
      "lstm-decoder/RNN/MultiRNNC2DCell/Cell0/LSTMC2DCell/Conv_x/j/W:0       |    36864\n",
      "lstm-decoder/RNN/MultiRNNC2DCell/Cell0/LSTMC2DCell/Conv_x/j/b:0       |       64\n",
      "lstm-decoder/RNN/MultiRNNC2DCell/Cell0/LSTMC2DCell/Conv_x/f/W:0       |    36864\n",
      "lstm-decoder/RNN/MultiRNNC2DCell/Cell0/LSTMC2DCell/Conv_x/f/b:0       |       64\n",
      "lstm-decoder/RNN/MultiRNNC2DCell/Cell0/LSTMC2DCell/Conv_x/o/W:0       |    36864\n",
      "lstm-decoder/RNN/MultiRNNC2DCell/Cell0/LSTMC2DCell/Conv_x/o/b:0       |       64\n",
      "lstm-decoder/RNN/MultiRNNC2DCell/Cell0/LSTMC2DCell/Conv_h/i/W:0       |   102400\n",
      "lstm-decoder/RNN/MultiRNNC2DCell/Cell0/LSTMC2DCell/Conv_h/j/W:0       |   102400\n",
      "lstm-decoder/RNN/MultiRNNC2DCell/Cell0/LSTMC2DCell/Conv_h/f/W:0       |   102400\n",
      "lstm-decoder/RNN/MultiRNNC2DCell/Cell0/LSTMC2DCell/Conv_h/o/W:0       |   102400\n",
      "lstm-decoder/RNN/MultiRNNC2DCell/Cell0/LSTMC2DCell/Conv_peep/i/W:0    |   102400\n",
      "lstm-decoder/RNN/MultiRNNC2DCell/Cell0/LSTMC2DCell/Conv_peep/f/W:0    |   102400\n",
      "lstm-decoder/RNN/MultiRNNC2DCell/Cell0/LSTMC2DCell/Conv_peep/o/W:0    |   102400\n",
      "lstm-decoder/RNN/MultiRNNC2DCell/Cell1/LSTMC2DCell/Conv_x/i/W:0       |    36864\n",
      "lstm-decoder/RNN/MultiRNNC2DCell/Cell1/LSTMC2DCell/Conv_x/i/b:0       |       64\n",
      "lstm-decoder/RNN/MultiRNNC2DCell/Cell1/LSTMC2DCell/Conv_x/j/W:0       |    36864\n",
      "lstm-decoder/RNN/MultiRNNC2DCell/Cell1/LSTMC2DCell/Conv_x/j/b:0       |       64\n",
      "lstm-decoder/RNN/MultiRNNC2DCell/Cell1/LSTMC2DCell/Conv_x/f/W:0       |    36864\n",
      "lstm-decoder/RNN/MultiRNNC2DCell/Cell1/LSTMC2DCell/Conv_x/f/b:0       |       64\n",
      "lstm-decoder/RNN/MultiRNNC2DCell/Cell1/LSTMC2DCell/Conv_x/o/W:0       |    36864\n",
      "lstm-decoder/RNN/MultiRNNC2DCell/Cell1/LSTMC2DCell/Conv_x/o/b:0       |       64\n",
      "lstm-decoder/RNN/MultiRNNC2DCell/Cell1/LSTMC2DCell/Conv_h/i/W:0       |   102400\n",
      "lstm-decoder/RNN/MultiRNNC2DCell/Cell1/LSTMC2DCell/Conv_h/j/W:0       |   102400\n",
      "lstm-decoder/RNN/MultiRNNC2DCell/Cell1/LSTMC2DCell/Conv_h/f/W:0       |   102400\n",
      "lstm-decoder/RNN/MultiRNNC2DCell/Cell1/LSTMC2DCell/Conv_h/o/W:0       |   102400\n",
      "lstm-decoder/RNN/MultiRNNC2DCell/Cell1/LSTMC2DCell/Conv_peep/i/W:0    |   102400\n",
      "lstm-decoder/RNN/MultiRNNC2DCell/Cell1/LSTMC2DCell/Conv_peep/f/W:0    |   102400\n",
      "lstm-decoder/RNN/MultiRNNC2DCell/Cell1/LSTMC2DCell/Conv_peep/o/W:0    |   102400\n",
      "conv-decoder/deconv1_bn/beta:0                                        |       64\n",
      "conv-decoder/deconv1/W:0                                              |    36864\n",
      "conv-decoder/deconv1/b:0                                              |       64\n",
      "conv-decoder/deconv2_bn/beta:0                                        |       64\n",
      "conv-decoder/deconv2/W:0                                              |    18432\n",
      "conv-decoder/deconv2/b:0                                              |       32\n",
      "conv-decoder/deconv3_bn/beta:0                                        |       32\n",
      "conv-decoder/deconv3/W:0                                              |     2400\n",
      "conv-decoder/deconv3/b:0                                              |        3\n",
      "--------------------------------------------------------------------------------\n",
      "conv-decoder                                                          |    57955\n",
      "lstm-encoder                                                          |  1729024\n",
      "conv-encoder                                                          |    58016\n",
      "lstm-decoder                                                          |  1729024\n",
      "================================================================================\n",
      "TOTAL                                                                 |  3574019\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "runtime.build(restore_checkpoint=CHECKPOINT, restore_model_params=True,\n",
    "              restore_ema_variables=False, eval_mode=True, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "runtime.validate(EVAL_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@100000: Starting test (batch-size: 50, dataset-size: 13056):\n",
      "100%▕██████████▏- 754s - loss: 0.0066 - psnr: 50.1164 - ssim9: 0.9828 - f1-mae: 0.0025 - f1-ssim5: 0.9893 - sharpdiff: 29.9851 - bce: 0.3785 - ssim7: 0.9828 - f2-mae: 0.0031 - ssim: 0.9829 - f2-psnr: 50.5941 - f2-mse: 9.0715e-04 - ssim5: 0.9833 - msssim: 0.9844 - f1-mse: 6.2366e-04 - mae: 0.0040 - rsse: 3.3069 - f1-sharpdiff: 30.0961 - f1-psnr: 50.5197 - mse: 0.0016 - f2-sharpdiff: 30.1816 - f2-ssim5: 0.9860   \n"
     ]
    }
   ],
   "source": [
    "runtime.test(EVAL_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations\n",
    "On which dataset we want to test on on the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_eval = dataset_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random prediction\n",
    "Either as **binary** (like in training) or **float** (as in raw dataset)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_animation(dir_path, inputs, targets, predictions, fps):\n",
    "    concat_tgt = np.concatenate((inputs, targets))\n",
    "    concat_pred = np.concatenate((inputs, predictions))\n",
    "\n",
    "    tt.utils.video.write_multi_gif(os.path.join(dir_path, \"anim-{:02d}.gif\".format(i)),\n",
    "                                   [concat_tgt, concat_pred],\n",
    "                                   fps=fps, pad_value=1.0)\n",
    "\n",
    "    tt.utils.video.write_multi_image_sequence(os.path.join(dir_path, \"timeline-{:02d}.png\".format(i)),\n",
    "                                              [concat_tgt, concat_pred],\n",
    "                                              pad_value=1.0)\n",
    "\n",
    "def show(inputs, targets, predictions, rows=2):\n",
    "    tt.visualization.display_batch(inputs, ncols=5, nrows=rows, title=\"Inputs\")\n",
    "    tt.visualization.display_batch(targets, ncols=5, nrows=rows, title=\"Targets\")\n",
    "    tt.visualization.display_batch(predictions, ncols=5, nrows=rows, title=\"Predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dir_path = os.path.join(runtime.train_dir, OUT_DIR_NAME, \"random\")\n",
    "\n",
    "inputs, targets = dataset_eval.get_batch(NUM_SAMPLES)\n",
    "\n",
    "predictions = runtime.predict(inputs)\n",
    "\n",
    "show(inputs[0], targets[0], predictions[0])\n",
    "for i in range(inputs.shape[0]):\n",
    "    write_animation(dir_path, inputs[i], targets[i], predictions[i], GIF_FPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specific Predictions TBD !!!\n",
    "We are using the inputs used in _Gitgub: Adversarial Video Generation_ cropped out of the website. These consist of two sequences..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SOURCE_PATH = \"assets/other/pacman/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_sequence(dir_path, seq_id):\n",
    "    image_list = []\n",
    "    for i in range(INPUT_SEQ_LENGTH+OUTPUT_SEQ_LENGTH):\n",
    "        image_path = os.path.join(dir_path, str(seq_id), \"{:02d}.png\".format(i))\n",
    "        image = tt.utils.image.read(image_path, color_flags = cv2.IMREAD_GRAYSCALE)\n",
    "        image_list.append(image)\n",
    "    seq = np.array(image_list)\n",
    "    seq = seq / 255.0\n",
    "    seq = np.expand_dims(seq, 0)\n",
    "    return seq[:,:INPUT_SEQ_LENGTH] , seq[:,INPUT_SEQ_LENGTH:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dir_path = os.path.join(runtime.train_dir, OUT_DIR_NAME, \"spec\")\n",
    "\n",
    "for i in range(6):\n",
    "    inputs, targets = read_sequence(SOURCE_PATH, i)\n",
    "    predictions = runtime.predict(inputs)\n",
    "    \n",
    "    show(inputs[0], targets[0], predictions[0])\n",
    "    write_animation(dir_path, inputs[0], targets[0], predictions[0], GIF_FPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Fulll Image\n",
    "Is the FCN model worth it? :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_valid = tt.datasets.ms_pacman.MsPacmanValidDataset(DATA_DIR,\n",
    "                                                           input_seq_length=INPUT_SEQ_LENGTH,\n",
    "                                                           target_seq_length=OUTPUT_SEQ_LENGTH,\n",
    "                                                           skip_less_movement=False,\n",
    "                                                           random_flip=False)\n",
    "dataset_test = tt.datasets.ms_pacman.MsPacmanTestDataset(DATA_DIR,\n",
    "                                                         input_seq_length=INPUT_SEQ_LENGTH,\n",
    "                                                         target_seq_length=OUTPUT_SEQ_LENGTH,\n",
    "                                                         skip_less_movement=False,\n",
    "                                                         random_flip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_eval = dataset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "runtime.register_datasets(None, dataset_valid, dataset_test)\n",
    "runtime.build(restore_checkpoint=CHECKPOINT, restore_model_params=True,\n",
    "              restore_ema_variables=False, eval_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dir_path = os.path.join(runtime.train_dir, OUT_DIR_NAME, \"full\")\n",
    "\n",
    "inputs, targets = dataset_eval.get_batch(NUM_SAMPLES)\n",
    "\n",
    "predictions = runtime.predict(inputs)\n",
    "\n",
    "show(inputs[0], targets[0], predictions[0])\n",
    "for i in range(inputs.shape[0]):\n",
    "    write_animation(dir_path, inputs[i], targets[i], predictions[i], GIF_FPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Full Image - Longer Time Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data\n",
    "INPUT_SEQ_LENGTH = 8\n",
    "OUTPUT_SEQ_LENGTH = 24\n",
    "\n",
    "dataset_valid = tt.datasets.ms_pacman.MsPacmanValidDataset(DATA_DIR,\n",
    "                                                           input_seq_length=INPUT_SEQ_LENGTH,\n",
    "                                                           target_seq_length=OUTPUT_SEQ_LENGTH,\n",
    "                                                           skip_less_movement=False,\n",
    "                                                           random_flip=False)\n",
    "dataset_test = tt.datasets.ms_pacman.MsPacmanTestDataset(DATA_DIR,\n",
    "                                                         input_seq_length=INPUT_SEQ_LENGTH,\n",
    "                                                         target_seq_length=OUTPUT_SEQ_LENGTH,\n",
    "                                                         skip_less_movement=False,\n",
    "                                                         random_flip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_eval = dataset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "runtime.register_datasets(None, dataset_valid, dataset_test)\n",
    "runtime.build(restore_checkpoint=CHECKPOINT, restore_model_params=True,\n",
    "              restore_ema_variables=False, eval_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dir_path = os.path.join(runtime.train_dir, OUT_DIR_NAME, \"full-long\")\n",
    "\n",
    "inputs, targets = dataset_eval.get_batch(NUM_SAMPLES)\n",
    "\n",
    "predictions = runtime.predict(inputs)\n",
    "\n",
    "show(inputs[0], targets[0], predictions[0])\n",
    "for i in range(inputs.shape[0]):\n",
    "    write_animation(dir_path, inputs[i], targets[i], predictions[i], GIF_FPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
