{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMSEQ TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Force matplotlib to use inline rendering\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# add path to libraries for ipython\n",
    "sys.path.append(os.path.expanduser(\"~/libs\"))\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensortools as tt\n",
    "\n",
    "from model.conv_lstmconv2d_encoder_decoder import ConvLSTMConv2DDecoderEncoderModel\n",
    "from model.lstmconv2d_encoder_decoder import LSTMConv2DDecoderEncoderModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR = \"train/conv_c2dlstm_bce_no-nonlin-low_decay_5x5lstm\"\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "REG_LAMBDA = 1e-7\n",
    "NUM_GPUS = 2\n",
    "\n",
    "INPUT_SEQ_LENGTH = 10\n",
    "OUTPUT_SEQ_LENGTH = 10\n",
    "\n",
    "INITIAL_LR = 0.001\n",
    "LR_DECAY_STEP_INTERVAL = 10000\n",
    "LR_DECAY_FACTOR = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File mnist.h5 has already been downloaded.\n",
      "File mnist.h5 has already been downloaded.\n"
     ]
    }
   ],
   "source": [
    "dataset_train = tt.datasets.moving_mnist.MovingMNISTTrainDataset(input_shape=[INPUT_SEQ_LENGTH, 64, 64, 1],\n",
    "                                                                 target_shape=[OUTPUT_SEQ_LENGTH, 64, 64, 1])\n",
    "dataset_valid = tt.datasets.moving_mnist.MovingMNISTValidDataset(input_shape=[INPUT_SEQ_LENGTH, 64, 64, 1],\n",
    "                                                                 target_shape=[OUTPUT_SEQ_LENGTH, 64, 64, 1])\n",
    "#dataset_test = tt.datasets.moving_mnist.MovingMNISTTestDataset(input_seq_length=INPUT_SEQ_LENGTH,\n",
    "#                                                               target_seq_length=OUTPUT_SEQ_LENGTH)\n",
    "dataset_test = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launing default runtime...\n",
      "Selecting GPU device: 1\n"
     ]
    }
   ],
   "source": [
    "tt.hardware.set_cuda_devices([1])\n",
    "\n",
    "runtime = tt.core.DefaultRuntime(train_dir=TRAIN_DIR)\n",
    "#runtime = tt.core.MultiGpuRuntime(NUM_GPUS, train_dir=TRAIN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvStack/Conv1/W:0: 800\n",
      "ConvStack/Conv1/b:0: 32\n",
      "ConvStack/Conv2/W:0: 18432\n",
      "ConvStack/Conv2/b:0: 64\n",
      "ConvStack/Conv3/W:0: 36864\n",
      "ConvStack/Conv3/b:0: 64\n",
      "encoder-lstm/RNNConv2D/BasicLSTMConv2DCell/Conv_xi/W:0: 102400\n",
      "encoder-lstm/RNNConv2D/BasicLSTMConv2DCell/Conv_xi/b:0: 64\n",
      "encoder-lstm/RNNConv2D/BasicLSTMConv2DCell/Conv_xj/W:0: 102400\n",
      "encoder-lstm/RNNConv2D/BasicLSTMConv2DCell/Conv_xj/b:0: 64\n",
      "encoder-lstm/RNNConv2D/BasicLSTMConv2DCell/Conv_xf/W:0: 102400\n",
      "encoder-lstm/RNNConv2D/BasicLSTMConv2DCell/Conv_xf/b:0: 64\n",
      "encoder-lstm/RNNConv2D/BasicLSTMConv2DCell/Conv_xo/W:0: 102400\n",
      "encoder-lstm/RNNConv2D/BasicLSTMConv2DCell/Conv_xo/b:0: 64\n",
      "encoder-lstm/RNNConv2D/BasicLSTMConv2DCell/Conv_hi/W:0: 102400\n",
      "encoder-lstm/RNNConv2D/BasicLSTMConv2DCell/Conv_hj/W:0: 102400\n",
      "encoder-lstm/RNNConv2D/BasicLSTMConv2DCell/Conv_hf/W:0: 102400\n",
      "encoder-lstm/RNNConv2D/BasicLSTMConv2DCell/Conv_ho/W:0: 102400\n",
      "decoder-lstm/RNNConv2D/BasicLSTMConv2DCell/Conv_xi/W:0: 102400\n",
      "decoder-lstm/RNNConv2D/BasicLSTMConv2DCell/Conv_xi/b:0: 64\n",
      "decoder-lstm/RNNConv2D/BasicLSTMConv2DCell/Conv_xj/W:0: 102400\n",
      "decoder-lstm/RNNConv2D/BasicLSTMConv2DCell/Conv_xj/b:0: 64\n",
      "decoder-lstm/RNNConv2D/BasicLSTMConv2DCell/Conv_xf/W:0: 102400\n",
      "decoder-lstm/RNNConv2D/BasicLSTMConv2DCell/Conv_xf/b:0: 64\n",
      "decoder-lstm/RNNConv2D/BasicLSTMConv2DCell/Conv_xo/W:0: 102400\n",
      "decoder-lstm/RNNConv2D/BasicLSTMConv2DCell/Conv_xo/b:0: 64\n",
      "decoder-lstm/RNNConv2D/BasicLSTMConv2DCell/Conv_hi/W:0: 102400\n",
      "decoder-lstm/RNNConv2D/BasicLSTMConv2DCell/Conv_hj/W:0: 102400\n",
      "decoder-lstm/RNNConv2D/BasicLSTMConv2DCell/Conv_hf/W:0: 102400\n",
      "decoder-lstm/RNNConv2D/BasicLSTMConv2DCell/Conv_ho/W:0: 102400\n",
      "DeconvStack/Deconv1/W:0: 36864\n",
      "DeconvStack/Deconv1/b:0: 64\n",
      "DeconvStack/Deconv2/W:0: 36864\n",
      "DeconvStack/Deconv2/b:0: 32\n",
      "DeconvStack/Deconv3/W:0: 1600\n",
      "DeconvStack/Deconv3/b:0: 1\n",
      "----------------------------------------\n",
      "Total model-params: 1770593\n"
     ]
    }
   ],
   "source": [
    "runtime.register_datasets(dataset_train, dataset_valid, dataset_test)\n",
    "runtime.register_model(ConvLSTMConv2DDecoderEncoderModel(reg_lambda=REG_LAMBDA))\n",
    "#runtime.register_model(LSTMConv2DDecoderEncoderModel(reg_lambda=REG_LAMBDA))\n",
    "runtime.build(INITIAL_LR,\n",
    "              LR_DECAY_STEP_INTERVAL,\n",
    "              LR_DECAY_FACTOR,\n",
    "              verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_gifs(rt, dataset, gstep):\n",
    "    x, y = dataset.get_batch(1)\n",
    "    pred = rt.predict(x)\n",
    "\n",
    "    # concat x to y and prediction\n",
    "    concat_y = np.concatenate((x[0], y[0]))\n",
    "    concat_pred = np.concatenate((x[0], pred[0]))\n",
    "\n",
    "    tt.utils.video.write_multi_gif(os.path.join(rt.train_dir, \"out/anim-{:06d}.gif\".format(gstep)),\n",
    "                                   [concat_y * 255, concat_pred * 255],\n",
    "                                   fps=4)\n",
    "    \n",
    "def on_valid(rt, gstep):\n",
    "    write_gifs(rt, rt.datasets.valid, gstep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1...\n",
      "@    10: loss:     0.309, total-loss:     0.309 (   72.0 examples/sec,  0.44 sec/batch)\n",
      "@    20: loss:     0.211, total-loss:     0.211 (   71.3 examples/sec,  0.45 sec/batch)\n",
      "@    30: loss:     0.196, total-loss:     0.196 (   72.1 examples/sec,  0.44 sec/batch)\n",
      "@    40: loss:     0.183, total-loss:     0.183 (   72.1 examples/sec,  0.44 sec/batch)\n",
      "@    50: loss:     0.177, total-loss:     0.177 (   70.7 examples/sec,  0.45 sec/batch)\n",
      "@    60: loss:     0.174, total-loss:     0.174 (   74.7 examples/sec,  0.43 sec/batch)\n",
      "@    70: loss:     0.168, total-loss:     0.168 (   73.4 examples/sec,  0.44 sec/batch)\n",
      "@    80: loss:     0.170, total-loss:     0.170 (   73.5 examples/sec,  0.44 sec/batch)\n",
      "@    90: loss:     0.164, total-loss:     0.164 (   73.1 examples/sec,  0.44 sec/batch)\n"
     ]
    }
   ],
   "source": [
    "runtime.train(BATCH_SIZE, steps=50000, on_validate=on_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "runtime.validate(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "runtime.test(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x, y = dataset_valid.get_batch(1)\n",
    "pred = runtime.predict(x)\n",
    "\n",
    "tt.visualization.display_batch(x[0] * 255, nrows=2, ncols=5, title=\"Input\")\n",
    "tt.visualization.display_batch(y[0] * 1000, nrows=2, ncols=5, title=\"GT-Future\")\n",
    "tt.visualization.display_batch(pred[0] * 1000, nrows=2, ncols=5, title=\"GT-Prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "write_gifs(runtime, dataset_valid, 999999999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Terminate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "runtime.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
