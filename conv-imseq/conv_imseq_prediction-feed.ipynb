{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# add path to libraries for ipython\n",
    "sys.path.append(os.path.expanduser(\"~/libs\"))\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "import cv2\n",
    "from scipy.misc import imresize\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensortools as tt\n",
    "\n",
    "from model.conv_deconv_model import ConvDeconvModel\n",
    "from model.conv_lstm_model import ConvLSTMModel\n",
    "from model.conv_lstmconv2d_model import ConvLSTMConv2DModel\n",
    "from model.lstm_encoder_decoder import LSTMDecoderEncoderModel\n",
    "from model.lstmconv2d_encoder_decoder import LSTMConv2DDecoderEncoderModel\n",
    "from model.conv_lstmconv2d_encoder_decoder import ConvLSTMConv2DDecoderEncoderModel\n",
    "from model.conv_lstmconv2d_encoder_decoder_v2 import ConvLSTMConv2DDecoderEncoderModelV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR = 'train_moving_mnist_lstmconv2d_en_decoder'\n",
    "CHECKPOINT_FILE = 'model.ckpt-47000'\n",
    "VIDEO_OUTPUT_NAME = 'out/predicted_video_train_on_prev_lstmconv2d_ssim_mse.avi'\n",
    "\n",
    "INPUT_SEQ_LENGTH = 10\n",
    "\n",
    "PREDICTION_LENGTH = 10\n",
    "\n",
    "FRAME_WIDTH = 64\n",
    "FRAME_HEIGHT = 64\n",
    "FRAME_CHANNELS = 1\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "GPU_MEMORY_FRACTION = 1.0\n",
    "GPU_ALLOW_GROWTH = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File mnist.h5 has already been downloaded.\n"
     ]
    }
   ],
   "source": [
    "# dataset_train = tt.datasets.moving_mnist.MovingMNISTTrainDataset(BATCH_SIZE,\n",
    "#                                                                  INPUT_SEQ_LENGTH + PREDICTION_LENGTH)\n",
    "dataset_valid = tt.datasets.moving_mnist.MovingMNISTValidDataset(BATCH_SIZE,\n",
    "                                                                 INPUT_SEQ_LENGTH + PREDICTION_LENGTH,\n",
    "                                                                 num_digits=2)\n",
    "#dataset_test = tt.datasets.moving_mnist.MovingMNISTTestDataset(BATCH_SIZE,\n",
    "#                                                               INPUT_SEQ_LENGTH + PREDICTION_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('total error', 11.68919)\n",
      "('error', 11.687532)\n",
      "('min', -0.21953911)\n",
      "('max', 0.97124642)\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    seq_batch = tf.placeholder(tf.float32, shape=[None, INPUT_SEQ_LENGTH, FRAME_HEIGHT, FRAME_WIDTH, FRAME_CHANNELS])\n",
    "    pred_batch = tf.placeholder(tf.float32, shape=[None, PREDICTION_LENGTH, FRAME_HEIGHT, FRAME_WIDTH, FRAME_CHANNELS])\n",
    "    \n",
    "    # build graph and compute predictions from the inference model\n",
    "    model = LSTMConv2DDecoderEncoderModel(seq_batch, pred_batch,\n",
    "                                          lstm_layers=1,\n",
    "                                          lstm_filters=32)\n",
    "    \n",
    "    total_loss = model.total_loss\n",
    "    loss = model.loss\n",
    "\n",
    "    # Create a saver and merge all summaries\n",
    "    saver = tf.train.Saver(tf.all_variables())\n",
    "\n",
    "    # Create a session for running operations in the Graph\n",
    "    gpu_options = tf.GPUOptions(\n",
    "        per_process_gpu_memory_fraction=GPU_MEMORY_FRACTION,\n",
    "        allow_growth=GPU_ALLOW_GROWTH)\n",
    "    with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:\n",
    "        checkpoint_path = os.path.join(TRAIN_DIR, CHECKPOINT_FILE)\n",
    "        saver.restore(sess, checkpoint_path)\n",
    "        \n",
    "        with tt.utils.video.VideoWriter(\n",
    "            VIDEO_OUTPUT_NAME,\n",
    "            fps=10,\n",
    "            frame_size=(FRAME_HEIGHT, FRAME_WIDTH),\n",
    "            is_color=False if FRAME_CHANNELS == 1 else True) as vw:\n",
    "\n",
    "            input_frames = dataset_valid.get_batch()\n",
    "\n",
    "            for i in xrange(INPUT_SEQ_LENGTH):\n",
    "                frame = input_frames[0,i,:,:,:]\n",
    "\n",
    "                # if FRAME_CHANNELS == 1:\n",
    "                    # frame = tt.utils.image.to_grayscale(frame)\n",
    "\n",
    "                if frame is not None:\n",
    "                    frame = frame * 255\n",
    "                    frame = np.concatenate((frame, frame), axis=1)\n",
    "                    frame = frame.astype(np.uint8)\n",
    "                    vw.write_frame(frame)\n",
    "                \n",
    "                else:\n",
    "                    print('Warning: Error while reading frame.')\n",
    "\n",
    "            # insert an empty frame in between:\n",
    "            #black_frame = np.zeros((FRAME_HEIGHT, FRAME_WIDTH * 2, FRAME_CHANNELS), dtype=np.uint8) \n",
    "            #vw.write_frame(black_frame)\n",
    "            #vw.write_frame(black_frame)\n",
    "            \n",
    "            predicted_frames, total_error, error = sess.run([model.predictions, total_loss, loss],\n",
    "                                                            feed_dict={seq_batch: input_frames[:,0:INPUT_SEQ_LENGTH,:,:,:],\n",
    "                                                                       pred_batch: input_frames[:,INPUT_SEQ_LENGTH:INPUT_SEQ_LENGTH+PREDICTION_LENGTH,:,:,:]})\n",
    "            print('total error', total_error)\n",
    "            print('error', error)\n",
    "            \n",
    "            print(\"min\", np.min(predicted_frames))\n",
    "            print(\"max\", np.max(predicted_frames))\n",
    "\n",
    "            for j in xrange(PREDICTION_LENGTH):\n",
    "                predicted_frame = predicted_frames[0,j,:,:,:]\n",
    "                gt_frame = input_frames[0,INPUT_SEQ_LENGTH + j,:,:,:]\n",
    "                np.place(predicted_frame, predicted_frame > 1, [1])\n",
    "                np.place(predicted_frame, predicted_frame < 0, [0])\n",
    "                frame = np.concatenate((predicted_frame, gt_frame), axis=1)\n",
    "                frame = frame * 255\n",
    "                frame = frame.astype(np.uint8)\n",
    "                vw.write_frame(frame)\n",
    "\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
