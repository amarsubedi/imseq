{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "\n",
    "import cv2\n",
    "from scipy.misc import imresize\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# import model.conv_deconv_model as model\n",
    "import model.conv_lstm_model as model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# VIDEO_FILE = 'tmp/UCF11_updated_mpg/golf_swing/v_golf_10/v_golf_10_02.mpg'\n",
    "VIDEO_FILE = 'tmp/UCF11_updated_mpg/tennis_swing/v_tennis_01/v_tennis_01_01.mpg'\n",
    "# VIDEO_FILE = 'tmp/UCF11_updated_mpg/golf_swing/v_golf_14/v_golf_14_03.mpg' # Overfitting file\n",
    "VIDEO_START_FRAME = 0 \n",
    "\n",
    "TRAIN_DIR = 'train_30k_lstm_120_160_euc_loss'\n",
    "CHECKPOINT_FILE = 'model.ckpt-30000'\n",
    "VIDEO_OUTPUT_NAME = 'predicted_video'\n",
    "\n",
    "INPUT_SEQ_LENGTH = 5\n",
    "\n",
    "PREDICTION_LENGTH = 120\n",
    "GROUND_TRUTH_LENGTH = 30\n",
    "\n",
    "FRAME_SCALE_FACTOR = 0.2\n",
    "FRAME_WIDTH = int(320 * FRAME_SCALE_FACTOR)\n",
    "FRAME_HEIGHT = int(240 * FRAME_SCALE_FACTOR)\n",
    "FRAME_CHANNELS = 3\n",
    "\n",
    "LAMBDA = 5e-4\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "GPU_MEMORY_FRACTION = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: refactor\n",
    "def open_video(videofile, from_time=0):\n",
    "    vidcap = cv2.VideoCapture(videofile)\n",
    "    if from_time != 0:\n",
    "        vidcap.set(cv2.CAP_PROP_POS_MSEC, from_time)\n",
    "    return vidcap\n",
    "\n",
    "# TODO: refactor\n",
    "def read_next_frame(vidcap):\n",
    "    success, image = vidcap.read()\n",
    "    if success:\n",
    "        image = imresize(image, FRAME_SCALE_FACTOR)\n",
    "        return image\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_video_writer(filename):\n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.cv.CV_FOURCC(*'XVID')\n",
    "    out = cv2.VideoWriter('{}.avi'.format(filename), fourcc, 24.0, (max(128, FRAME_WIDTH), max(128, FRAME_HEIGHT)))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FF_MIN_BUFFER_SIZE = 16384  # from OpenCV C++ code\n",
    "\n",
    "def ensure_minimum_framesize(frame):\n",
    "    h, w, c = np.shape(frame)\n",
    "    size = h * w * c\n",
    "    if (size < FF_MIN_BUFFER_SIZE):\n",
    "        min_h = min_w = math.sqrt(FF_MIN_BUFFER_SIZE)\n",
    "        outframe = np.zeros([min_h, min_w, c], np.uint8)\n",
    "        top = (min_h - h) // 2\n",
    "        left = (min_w - w) // 2\n",
    "        outframe[top:(top + h), left:(left + w),:] = frame\n",
    "        frame = outframe     \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/stud/sauterme/.local/lib/python2.7/site-packages/ipykernel/__main__.py:8: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/usr/stud/sauterme/.local/lib/python2.7/site-packages/ipykernel/__main__.py:11: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128, 3)\n",
      "(128, 128, 3)\n",
      "(128, 128, 3)\n",
      "(128, 128, 3)\n",
      "(128, 128, 3)\n",
      "(128, 128, 3)\n",
      "(128, 128, 3)\n",
      "(128, 128, 3)\n",
      "(128, 128, 3)\n",
      "(128, 128, 3)\n",
      "(128, 128, 3)\n",
      "(128, 128, 3)\n",
      "(128, 128, 3)\n",
      "(128, 128, 3)\n",
      "(128, 128, 3)\n",
      "(128, 128, 3)\n",
      "(128, 128, 3)\n",
      "(128, 128, 3)\n",
      "(128, 128, 3)\n",
      "(128, 128, 3)\n",
      "(128, 128, 3)\n",
      "(128, 128, 3)\n",
      "(128, 128, 3)\n",
      "(128, 128, 3)\n",
      "(128, 128, 3)\n",
      "(128, 128, 3)\n",
      "(128, 128, 3)\n",
      "(128, 128, 3)\n",
      "(128, 128, 3)\n",
      "(128, 128, 3)\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    seq_batch = tf.placeholder(tf.float32, shape=[1, FRAME_HEIGHT, FRAME_WIDTH, FRAME_CHANNELS * INPUT_SEQ_LENGTH])\n",
    "    \n",
    "    # build graph and compute predictions from the inference model\n",
    "    model_output = model.inference(seq_batch, BATCH_SIZE, FRAME_HEIGHT, FRAME_WIDTH, FRAME_CHANNELS,\n",
    "                                   INPUT_SEQ_LENGTH, LAMBDA)\n",
    "\n",
    "    # Create a saver and merge all summaries\n",
    "    saver = tf.train.Saver(tf.all_variables())\n",
    "\n",
    "    # Create a session for running operations in the Graph\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=GPU_MEMORY_FRACTION)\n",
    "    with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:\n",
    "        checkpoint_path = os.path.join(TRAIN_DIR, CHECKPOINT_FILE)\n",
    "        saver.restore(sess, checkpoint_path)\n",
    "        \n",
    "        vidcap = open_video(VIDEO_FILE, VIDEO_START_FRAME)\n",
    "        vidwriter = get_video_writer(VIDEO_OUTPUT_NAME)\n",
    "        \n",
    "        input_frames = []\n",
    "        \n",
    "        for i in xrange(GROUND_TRUTH_LENGTH):\n",
    "            frame = read_next_frame(vidcap)\n",
    "            \n",
    "            if frame is not None:\n",
    "                vidframe = ensure_minimum_framesize(frame)\n",
    "                vidwriter.write(vidframe)\n",
    "\n",
    "                if i >= GROUND_TRUTH_LENGTH - INPUT_SEQ_LENGTH:\n",
    "                    frame = (frame - 128.0) / 128.0\n",
    "                    input_frames.append(frame)\n",
    "            else:\n",
    "                print('Warning: Error while reading frame.')\n",
    "                ensure_minimum_framesize\n",
    "        # insert an empty frame in between:\n",
    "        black_frame = np.zeros((FRAME_HEIGHT, FRAME_WIDTH, FRAME_CHANNELS), dtype=np.uint8) \n",
    "        black_frame = ensure_minimum_framesize(black_frame)\n",
    "        # vidwriter.write(black_frame)\n",
    "        # vidwriter.write(black_frame)\n",
    "        \n",
    "        for j in xrange(PREDICTION_LENGTH):\n",
    "            seq_input = input_frames[0]\n",
    "            for f in xrange(1, INPUT_SEQ_LENGTH):\n",
    "                seq_input = np.concatenate([seq_input, input_frames[f]], axis=2)\n",
    "            seq_input = np.expand_dims(seq_input, axis=0)\n",
    "            \n",
    "            predicted_frame = sess.run([model_output], feed_dict={seq_batch: seq_input})\n",
    "            predicted_frame = np.squeeze(predicted_frame)\n",
    "            np.place(predicted_frame, predicted_frame > 1, [1])\n",
    "            np.place(predicted_frame, predicted_frame < -1, [-1])\n",
    "            video_frame = predicted_frame * 128.0 + 128.0\n",
    "            np.place(video_frame, video_frame > 255, [255]) # values are 0-256?!\n",
    "            video_frame = video_frame.astype(np.uint8)\n",
    "            video_frame = ensure_minimum_framesize(video_frame)\n",
    "            vidwriter.write(video_frame)\n",
    "            \n",
    "            del input_frames[0]\n",
    "            input_frames.append(predicted_frame)\n",
    "            \n",
    "        vidwriter.release()\n",
    "        vidcap.release()\n",
    "        \n",
    "        print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
