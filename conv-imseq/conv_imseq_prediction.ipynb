{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import model.conv_deconv_model as model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# VIDEO_FILE = 'tmp/UCF11_updated_mpg/golf_swing/v_golf_10/v_golf_10_02.mpg'\n",
    "VIDEO_FILE = 'tmp/UCF11_updated_mpg/tennis_swing/v_tennis_01/v_tennis_01_01.mpg'\n",
    "VIDEO_START_FRAME = 0 \n",
    "\n",
    "TRAIN_DIR = 'train_10k_5seq'\n",
    "\n",
    "INPUT_SEQ_LENGTH = 5\n",
    "\n",
    "PREDICTION_LENGTH = 120\n",
    "GROUND_TRUTH_LENGTH = 30\n",
    "\n",
    "FRAME_WIDTH = 320\n",
    "FRAME_HEIGHT = 240\n",
    "FRAME_CHANNELS = 3\n",
    "\n",
    "LAMBDA = 5e-4\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "GPU_MEMORY_FRACTION = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: refactor\n",
    "def open_video(videofile, from_time=0):\n",
    "    vidcap = cv2.VideoCapture(videofile)\n",
    "    if from_time != 0:\n",
    "        vidcap.set(cv2.CAP_PROP_POS_MSEC, from_time)\n",
    "    return vidcap\n",
    "\n",
    "# TODO: refactor\n",
    "def read_next_frame(vidcap):\n",
    "    success, image = vidcap.read()\n",
    "    if success:\n",
    "        return image\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_video_writer(filename):\n",
    "    # Define the codec and create VideoWriter object\n",
    "    # fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    fourcc = cv2.cv.CV_FOURCC(*'XVID')\n",
    "    out = cv2.VideoWriter('{}.avi'.format(filename), fourcc, 24.0, (320,240))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Graph().as_default():\n",
    "    seq_batch = tf.placeholder(tf.float32, shape=[1, FRAME_HEIGHT, FRAME_WIDTH, FRAME_CHANNELS * INPUT_SEQ_LENGTH])\n",
    "    \n",
    "    # with tf.device(GPU_TO_USE):\n",
    "    # build graph and compute predictions from the inference model\n",
    "    model_output = model.inference(seq_batch, BATCH_SIZE, FRAME_HEIGHT, FRAME_WIDTH, FRAME_CHANNELS,\n",
    "                                   INPUT_SEQ_LENGTH, LAMBDA)\n",
    "\n",
    "    # Create a saver and merge all summaries\n",
    "    saver = tf.train.Saver(tf.all_variables())\n",
    "\n",
    "    # Create a session for running operations in the Graph\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=GPU_MEMORY_FRACTION)\n",
    "    with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:\n",
    "        checkpoint_path = os.path.join(TRAIN_DIR, 'model.ckpt-10000')\n",
    "        saver.restore(sess, checkpoint_path)\n",
    "        \n",
    "        vidcap = open_video(VIDEO_FILE, VIDEO_START_FRAME)\n",
    "        vidwriter = get_video_writer('predicted_video')\n",
    "        \n",
    "        input_frames = []\n",
    "        \n",
    "        for i in xrange(GROUND_TRUTH_LENGTH):\n",
    "            frame = read_next_frame(vidcap)\n",
    "            \n",
    "            if frame is not None:\n",
    "                vidwriter.write(frame)\n",
    "\n",
    "                if i >= GROUND_TRUTH_LENGTH - INPUT_SEQ_LENGTH:\n",
    "                    frame = (frame - 128.0) / 128.0\n",
    "                    input_frames.append(frame)\n",
    "            else:\n",
    "                print('Warning: Error while reading frame.')\n",
    "                \n",
    "        # insert an empty frame in between:\n",
    "        black_frame = np.zeros((FRAME_HEIGHT, FRAME_WIDTH, FRAME_CHANNELS), dtype=np.uint8) \n",
    "        vidwriter.write(black_frame)\n",
    "        vidwriter.write(black_frame)\n",
    "        \n",
    "        for j in xrange(PREDICTION_LENGTH):\n",
    "            seq_input = np.concatenate([input_frames[0], input_frames[1], input_frames[2], input_frames[3], input_frames[4]],\n",
    "                                       axis=2)\n",
    "            seq_input = np.expand_dims(seq_input, axis=0)\n",
    "            \n",
    "            predicted_frame = sess.run([model_output], feed_dict={seq_batch: seq_input})\n",
    "            predicted_frame = np.squeeze(predicted_frame)\n",
    "            np.place(predicted_frame, predicted_frame > 1, [1])\n",
    "            np.place(predicted_frame, predicted_frame < -1, [-1])\n",
    "            # print(np.min(predicted_frame))\n",
    "            # print(np.max(predicted_frame))\n",
    "            video_frame = predicted_frame * 128.0 + 128.0\n",
    "            np.place(video_frame, video_frame > 255, [255]) # values are 0-256?!\n",
    "            video_frame = video_frame.astype(np.uint8)\n",
    "            # print(np.min(video_frame))\n",
    "            # print(np.max(video_frame))\n",
    "            vidwriter.write(video_frame)\n",
    "            \n",
    "            del input_frames[0]\n",
    "            input_frames.append(predicted_frame)\n",
    "            \n",
    "        vidwriter.release()\n",
    "        vidcap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
